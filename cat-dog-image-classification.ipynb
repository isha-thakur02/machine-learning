{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9498291,"sourceType":"datasetVersion","datasetId":5421010}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Flatten, Dense, Dropout\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import EarlyStopping","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T03:44:03.287791Z","iopub.execute_input":"2025-02-21T03:44:03.288902Z","iopub.status.idle":"2025-02-21T03:44:20.949108Z","shell.execute_reply.started":"2025-02-21T03:44:03.288826Z","shell.execute_reply":"2025-02-21T03:44:20.947684Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"dataset_path = '/kaggle/input/dog-vs-cat/animals'\nimg_size = (150, 150)\nbatch_size = 32","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T03:44:20.950877Z","iopub.execute_input":"2025-02-21T03:44:20.951644Z","iopub.status.idle":"2025-02-21T03:44:20.957025Z","shell.execute_reply.started":"2025-02-21T03:44:20.951600Z","shell.execute_reply":"2025-02-21T03:44:20.955122Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n\ntrain_data = datagen.flow_from_directory(dataset_path, target_size=img_size, batch_size=batch_size, class_mode='binary', subset='training')\nval_data = datagen.flow_from_directory(dataset_path, target_size=img_size, batch_size=batch_size, class_mode='binary', subset='validation')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T03:44:20.959169Z","iopub.execute_input":"2025-02-21T03:44:20.959573Z","iopub.status.idle":"2025-02-21T03:44:22.448716Z","shell.execute_reply.started":"2025-02-21T03:44:20.959531Z","shell.execute_reply":"2025-02-21T03:44:22.447533Z"}},"outputs":[{"name":"stdout","text":"Found 800 images belonging to 2 classes.\nFound 200 images belonging to 2 classes.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"base_model = VGG16(weights=None, include_top=False, input_shape=(150, 150, 3))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T03:44:22.451018Z","iopub.execute_input":"2025-02-21T03:44:22.451345Z","iopub.status.idle":"2025-02-21T03:44:22.744892Z","shell.execute_reply.started":"2025-02-21T03:44:22.451319Z","shell.execute_reply":"2025-02-21T03:44:22.743561Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"model = Sequential()\nmodel.add(base_model)\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5)) \nmodel.add(Dense(1, activation='sigmoid')) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T03:44:22.745975Z","iopub.execute_input":"2025-02-21T03:44:22.746276Z","iopub.status.idle":"2025-02-21T03:44:22.808075Z","shell.execute_reply.started":"2025-02-21T03:44:22.746248Z","shell.execute_reply":"2025-02-21T03:44:22.806821Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T03:44:22.809519Z","iopub.execute_input":"2025-02-21T03:44:22.809965Z","iopub.status.idle":"2025-02-21T03:44:22.827039Z","shell.execute_reply.started":"2025-02-21T03:44:22.809925Z","shell.execute_reply":"2025-02-21T03:44:22.825842Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T03:44:22.828210Z","iopub.execute_input":"2025-02-21T03:44:22.828579Z","iopub.status.idle":"2025-02-21T03:44:22.835808Z","shell.execute_reply.started":"2025-02-21T03:44:22.828536Z","shell.execute_reply":"2025-02-21T03:44:22.834692Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"model.fit(train_data, validation_data=val_data, epochs=10, callbacks=[early_stop])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T03:44:22.837918Z","iopub.execute_input":"2025-02-21T03:44:22.838250Z","iopub.status.idle":"2025-02-21T04:15:33.630227Z","shell.execute_reply.started":"2025-02-21T03:44:22.838220Z","shell.execute_reply":"2025-02-21T04:15:33.628998Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 15s/step - accuracy: 0.4862 - loss: 0.6973 - val_accuracy: 0.5000 - val_loss: 0.6938\nEpoch 2/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 15s/step - accuracy: 0.4996 - loss: 0.6934 - val_accuracy: 0.5000 - val_loss: 0.6931\nEpoch 3/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m373s\u001b[0m 15s/step - accuracy: 0.4648 - loss: 0.6935 - val_accuracy: 0.5000 - val_loss: 0.6932\nEpoch 4/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 15s/step - accuracy: 0.5353 - loss: 0.6923 - val_accuracy: 0.5000 - val_loss: 0.6932\nEpoch 5/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 15s/step - accuracy: 0.4772 - loss: 0.6935 - val_accuracy: 0.5000 - val_loss: 0.6932\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x77fdd5a09840>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"model.save(\"/kaggle/working/vgg16_dog_vs_cat.h5\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T04:54:59.670285Z","iopub.execute_input":"2025-02-21T04:54:59.670841Z","iopub.status.idle":"2025-02-21T04:55:00.379199Z","shell.execute_reply.started":"2025-02-21T04:54:59.670740Z","shell.execute_reply":"2025-02-21T04:55:00.377896Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}